Hereâ€™s a detailed step-by-step guide for **Task 5: Improve Response Quality by Including Examples**:

---

### Task 5: Improve Response Quality by Including Examples

**Objective:** Enhance the accuracy and relevance of LLM responses by providing carefully selected examples within your prompt (also known as *few-shot prompting*).

---

#### âœ… Steps to Follow:

1. **Open the Notebook:**
   - In Vertex AI Workbench (JupyterLab), open the notebook section titled **â€œImprove response quality by including examples.â€**

---

#### ğŸ”¹ Understand Few-Shot Prompting:

- Few-shot prompting involves giving the model 1â€“5 **sample input-output pairs** in the prompt to help it learn how to respond.
- These examples act as *in-context training data*, guiding the model's response format, tone, and accuracy.

---

#### ğŸ”¹ Run the Section: Improve response quality by including examples

- Go through the cells in the **â€œImprove response quality by including examplesâ€** section.
- Run each cell to see how:
  - The quality of model outputs improves with relevant examples.
  - Including more than 5 examples may lead to *overfitting* or degraded performance.
- Observe how *example distribution* affects the performance:
  - For classification, ensure a **balanced number of examples** across all categories.
  - For general tasks, make sure examples **closely resemble real use cases**.

---

#### ğŸ›  Example Prompt Format:

```text
Input: What's the weather like in Paris?
Output: The weather in Paris is mostly sunny with a high of 21Â°C.

Input: What's the weather like in Tokyo?
Output: It's currently raining in Tokyo, with temperatures around 18Â°C.

Input: What's the weather like in New York?
Output:
```

- The model learns the format and style of the response from the examples.
- This technique reduces irrelevant responses and improves contextual accuracy.

---

âœ… **Click â€œCheck my progressâ€** to verify the completion of this objective.

---

#### ğŸ§  Key Takeaways:

- ğŸ“Œ Use **1â€“5 examples** to demonstrate how the model should respond.
- ğŸ¯ Ensure examples are **high-quality and relevant** to the use case.
- âš–ï¸ Maintain **balanced distribution** of examples to avoid bias.
- ğŸš« Avoid too many examples, which may cause overfitting or confusion.

---

This task shows how to implement *few-shot learning* using prompts, improving model reliability in real-world applications like support bots, data extractors, or recommendation engines.
